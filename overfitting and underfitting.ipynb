{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-block alert-success\">Homework 2 --- Group 5: Betty Chenï¼Œ Chenyi Zhang, Ruiyuan Luan, Shuang Peng</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.float_format',lambda x: '%.2f'%x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> Part I</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('home_data.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21613 entries, 7129300520 to 1523300157\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           21613 non-null  object \n",
      " 1   price          21613 non-null  int64  \n",
      " 2   bedrooms       21613 non-null  int64  \n",
      " 3   bathrooms      21613 non-null  float64\n",
      " 4   sqft_living    21613 non-null  int64  \n",
      " 5   sqft_lot       21613 non-null  int64  \n",
      " 6   floors         21613 non-null  float64\n",
      " 7   waterfront     21613 non-null  int64  \n",
      " 8   view           21613 non-null  int64  \n",
      " 9   condition      21613 non-null  int64  \n",
      " 10  grade          21613 non-null  int64  \n",
      " 11  sqft_above     21613 non-null  int64  \n",
      " 12  sqft_basement  21613 non-null  int64  \n",
      " 13  yr_built       21613 non-null  int64  \n",
      " 14  yr_renovated   21613 non-null  int64  \n",
      " 15  zipcode        21613 non-null  int64  \n",
      " 16  lat            21613 non-null  float64\n",
      " 17  long           21613 non-null  float64\n",
      " 18  sqft_living15  21613 non-null  int64  \n",
      " 19  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(4), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "      <td>21613.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>540088.14</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2079.90</td>\n",
       "      <td>15106.97</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.41</td>\n",
       "      <td>7.66</td>\n",
       "      <td>1788.39</td>\n",
       "      <td>291.51</td>\n",
       "      <td>1971.01</td>\n",
       "      <td>84.40</td>\n",
       "      <td>98077.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>-122.21</td>\n",
       "      <td>1986.55</td>\n",
       "      <td>12768.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>367127.20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>918.44</td>\n",
       "      <td>41420.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.18</td>\n",
       "      <td>828.09</td>\n",
       "      <td>442.58</td>\n",
       "      <td>29.37</td>\n",
       "      <td>401.68</td>\n",
       "      <td>53.51</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>685.39</td>\n",
       "      <td>27304.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>520.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98001.00</td>\n",
       "      <td>47.16</td>\n",
       "      <td>-122.52</td>\n",
       "      <td>399.00</td>\n",
       "      <td>651.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>321950.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1427.00</td>\n",
       "      <td>5040.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1190.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1951.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98033.00</td>\n",
       "      <td>47.47</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>1490.00</td>\n",
       "      <td>5100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>450000.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1910.00</td>\n",
       "      <td>7618.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1560.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1975.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98065.00</td>\n",
       "      <td>47.57</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>1840.00</td>\n",
       "      <td>7620.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>645000.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550.00</td>\n",
       "      <td>10688.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2210.00</td>\n",
       "      <td>560.00</td>\n",
       "      <td>1997.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98118.00</td>\n",
       "      <td>47.68</td>\n",
       "      <td>-122.12</td>\n",
       "      <td>2360.00</td>\n",
       "      <td>10083.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7700000.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>13540.00</td>\n",
       "      <td>1651359.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9410.00</td>\n",
       "      <td>4820.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>2015.00</td>\n",
       "      <td>98199.00</td>\n",
       "      <td>47.78</td>\n",
       "      <td>-121.31</td>\n",
       "      <td>6210.00</td>\n",
       "      <td>871200.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  bedrooms  bathrooms  sqft_living   sqft_lot   floors  \\\n",
       "count   21613.00  21613.00   21613.00     21613.00   21613.00 21613.00   \n",
       "mean   540088.14      3.37       2.11      2079.90   15106.97     1.49   \n",
       "std    367127.20      0.93       0.77       918.44   41420.51     0.54   \n",
       "min     75000.00      0.00       0.00       290.00     520.00     1.00   \n",
       "25%    321950.00      3.00       1.75      1427.00    5040.00     1.00   \n",
       "50%    450000.00      3.00       2.25      1910.00    7618.00     1.50   \n",
       "75%    645000.00      4.00       2.50      2550.00   10688.00     2.00   \n",
       "max   7700000.00     33.00       8.00     13540.00 1651359.00     3.50   \n",
       "\n",
       "       waterfront     view  condition    grade  sqft_above  sqft_basement  \\\n",
       "count    21613.00 21613.00   21613.00 21613.00    21613.00       21613.00   \n",
       "mean         0.01     0.23       3.41     7.66     1788.39         291.51   \n",
       "std          0.09     0.77       0.65     1.18      828.09         442.58   \n",
       "min          0.00     0.00       1.00     1.00      290.00           0.00   \n",
       "25%          0.00     0.00       3.00     7.00     1190.00           0.00   \n",
       "50%          0.00     0.00       3.00     7.00     1560.00           0.00   \n",
       "75%          0.00     0.00       4.00     8.00     2210.00         560.00   \n",
       "max          1.00     4.00       5.00    13.00     9410.00        4820.00   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "count  21613.00      21613.00 21613.00 21613.00 21613.00       21613.00   \n",
       "mean    1971.01         84.40 98077.94    47.56  -122.21        1986.55   \n",
       "std       29.37        401.68    53.51     0.14     0.14         685.39   \n",
       "min     1900.00          0.00 98001.00    47.16  -122.52         399.00   \n",
       "25%     1951.00          0.00 98033.00    47.47  -122.33        1490.00   \n",
       "50%     1975.00          0.00 98065.00    47.57  -122.23        1840.00   \n",
       "75%     1997.00          0.00 98118.00    47.68  -122.12        2360.00   \n",
       "max     2015.00       2015.00 98199.00    47.78  -121.31        6210.00   \n",
       "\n",
       "       sqft_lot15  \n",
       "count    21613.00  \n",
       "mean     12768.46  \n",
       "std      27304.18  \n",
       "min        651.00  \n",
       "25%       5100.00  \n",
       "50%       7620.00  \n",
       "75%      10083.00  \n",
       "max     871200.00  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add extra features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['bedrooms_squared']=housing.bedrooms*housing.bedrooms\n",
    "housing['bed_bath_rooms'] = housing.bedrooms*housing.bathrooms\n",
    "housing['log_sqft_living'] = np.log10(housing.sqft_living)\n",
    "housing['lat_plus_long'] = housing.lat+housing.long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms_squared</th>\n",
       "      <th>bed_bath_rooms</th>\n",
       "      <th>log_sqft_living</th>\n",
       "      <th>lat_plus_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.23</td>\n",
       "      <td>7.50</td>\n",
       "      <td>3.28</td>\n",
       "      <td>-74.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bedrooms_squared  bed_bath_rooms  log_sqft_living  lat_plus_long\n",
       "mean             12.23            7.50             3.28         -74.65"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()[1:2][['bedrooms_squared','bed_bath_rooms','log_sqft_living','lat_plus_long']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue>The mean values of four new variables are 12.23, 7.50, 3.28, -74.65."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= housing[['sqft_living', 'bedrooms','bathrooms','lat', 'long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=housing.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Estimate the regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model coeff (w): [ 3.12942011e+02 -5.30962684e+04  1.47770422e+04  6.53983345e+05\n",
      " -3.25707345e+05]\n",
      "linear model intercept (b): -70870847.444\n",
      "R-squared score: 0.590\n"
     ]
    }
   ],
   "source": [
    "print('linear model coeff (w): {}'\n",
    "     .format(linreg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('R-squared score: {:.3f}'\n",
    "     .format(linreg.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. RSS on trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_train_1 = (linreg.coef_ * X_train).sum(axis=1) + linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979843599527788.9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Price_train_1 - y_train)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. RSS on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_test_1 = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213487129853769.4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Price_test_1 - y_test)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= housing[['sqft_living', 'bedrooms','bathrooms','lat', 'long','bed_bath_rooms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=housing.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Estimate the regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model coeff (w): [ 3.06819574e+02 -1.04604713e+05 -7.01815223e+04  6.50590954e+05\n",
      " -3.09965761e+05  2.49441476e+04]\n",
      "linear model intercept (b): -68606821.793\n",
      "R-squared score: 0.594\n"
     ]
    }
   ],
   "source": [
    "print('linear model coeff (w): {}'\n",
    "     .format(linreg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('R-squared score: {:.3f}'\n",
    "     .format(linreg.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. RSS on trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_train_2 = (linreg.coef_ * X_train).sum(axis=1) + linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970799203211189.2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Price_train_2 - y_train)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. RSS on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_test_2 = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210778545075244.1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Price_test_2 - y_test)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= housing[['sqft_living', 'bedrooms','bathrooms','lat', 'long',\\\n",
    "            'bed_bath_rooms','bedrooms_squared','log_sqft_living','lat_plus_long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=housing.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Estimate the regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model coeff (w): [ 5.37808087e+02  2.78048472e+03  1.01363772e+05  5.30798411e+05\n",
      " -4.09655443e+05 -1.81822573e+04  7.24579880e+02 -1.31484522e+06\n",
      "  1.21142968e+05]\n",
      "linear model intercept (b): -62628451.678\n",
      "R-squared score: 0.616\n"
     ]
    }
   ],
   "source": [
    "print('linear model coeff (w): {}'\n",
    "     .format(linreg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('R-squared score: {:.3f}'\n",
    "     .format(linreg.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. RSS on trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_train_3 = (linreg.coef_ * X_train).sum(axis=1) + linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "913653648613737.6"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Price_train_3 - y_train)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. RSS on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_test_3 = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203972055451345.8"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Price_test_3 - y_test)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue>1. The sign for the coefficient for â€˜bathroomsâ€™ in Model 1 is positive.\n",
    "#### <font color=blue>2. The sign for the coefficient for â€˜bathroomsâ€™ in Model 2 is negative.\n",
    "#### <font color=blue>3. The signs of bathrooms in two models are not the same, because after we add bed_bath_rooms into model 3,it will change the fit of the model, as a result, the coefficients of the model will change.\n",
    "#### <font color=blue>4. Model 3's RSS on trainning data is the lowest.\n",
    "#### <font color=blue>5. Model 3's RSS on testing data is the lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validate-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=housing[['sqft_living']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=housing.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('polynomialfeatures',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('linearregression',\n",
       "                                        LinearRegression())]),\n",
       "             n_jobs=-1, param_grid={'polynomialfeatures__degree': range(1, 16)},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "pipe = make_pipeline(PolynomialFeatures(), StandardScaler(),LinearRegression()) \n",
    "param_grid = {'polynomialfeatures__degree': range(1,16)} \n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1,return_train_score=True) \n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>{'polynomialfeatures__degree': 1}</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>{'polynomialfeatures__degree': 2}</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>{'polynomialfeatures__degree': 3}</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>{'polynomialfeatures__degree': 4}</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.09</td>\n",
       "      <td>5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>{'polynomialfeatures__degree': 5}</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>{'polynomialfeatures__degree': 6}</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>{'polynomialfeatures__degree': 7}</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.82</td>\n",
       "      <td>8</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "      <td>{'polynomialfeatures__degree': 8}</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-2.98</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>1.41</td>\n",
       "      <td>9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>{'polynomialfeatures__degree': 9}</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>{'polynomialfeatures__degree': 10}</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>-29.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>11.68</td>\n",
       "      <td>10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>{'polynomialfeatures__degree': 11}</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-48.93</td>\n",
       "      <td>-1305.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-270.57</td>\n",
       "      <td>517.84</td>\n",
       "      <td>12</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>{'polynomialfeatures__degree': 12}</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-126.47</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>50.79</td>\n",
       "      <td>11</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>{'polynomialfeatures__degree': 13}</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-34.71</td>\n",
       "      <td>-44844.10</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-8975.44</td>\n",
       "      <td>17934.33</td>\n",
       "      <td>13</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>{'polynomialfeatures__degree': 14}</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-6821.87</td>\n",
       "      <td>-5755822.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-1152528.63</td>\n",
       "      <td>2301648.66</td>\n",
       "      <td>15</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>{'polynomialfeatures__degree': 15}</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-26146.05</td>\n",
       "      <td>-777769.11</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-160782.71</td>\n",
       "      <td>308659.36</td>\n",
       "      <td>14</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0            0.02          0.01             0.01            0.00   \n",
       "1            0.02          0.00             0.00            0.00   \n",
       "2            0.02          0.00             0.00            0.00   \n",
       "3            0.02          0.00             0.00            0.00   \n",
       "4            0.02          0.00             0.00            0.00   \n",
       "5            0.03          0.01             0.00            0.00   \n",
       "6            0.04          0.02             0.01            0.01   \n",
       "7            0.03          0.01             0.02            0.02   \n",
       "8            0.03          0.00             0.01            0.00   \n",
       "9            0.03          0.01             0.01            0.00   \n",
       "10           0.06          0.03             0.01            0.01   \n",
       "11           0.04          0.01             0.01            0.00   \n",
       "12           0.04          0.01             0.01            0.00   \n",
       "13           0.04          0.00             0.01            0.00   \n",
       "14           0.04          0.00             0.01            0.00   \n",
       "\n",
       "   param_polynomialfeatures__degree                              params  \\\n",
       "0                                 1   {'polynomialfeatures__degree': 1}   \n",
       "1                                 2   {'polynomialfeatures__degree': 2}   \n",
       "2                                 3   {'polynomialfeatures__degree': 3}   \n",
       "3                                 4   {'polynomialfeatures__degree': 4}   \n",
       "4                                 5   {'polynomialfeatures__degree': 5}   \n",
       "5                                 6   {'polynomialfeatures__degree': 6}   \n",
       "6                                 7   {'polynomialfeatures__degree': 7}   \n",
       "7                                 8   {'polynomialfeatures__degree': 8}   \n",
       "8                                 9   {'polynomialfeatures__degree': 9}   \n",
       "9                                10  {'polynomialfeatures__degree': 10}   \n",
       "10                               11  {'polynomialfeatures__degree': 11}   \n",
       "11                               12  {'polynomialfeatures__degree': 12}   \n",
       "12                               13  {'polynomialfeatures__degree': 13}   \n",
       "13                               14  {'polynomialfeatures__degree': 14}   \n",
       "14                               15  {'polynomialfeatures__degree': 15}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                0.49               0.51               0.48   \n",
       "1                0.54               0.59               0.42   \n",
       "2                0.54               0.57               0.42   \n",
       "3                0.54               0.57               0.33   \n",
       "4                0.55               0.59               0.33   \n",
       "5                0.55               0.60               0.39   \n",
       "6                0.55               0.60              -1.50   \n",
       "7                0.56               0.60              -2.98   \n",
       "8                0.56               0.61               0.09   \n",
       "9                0.56              -5.92             -29.59   \n",
       "10               0.55             -48.93           -1305.54   \n",
       "11               0.55               0.42            -126.47   \n",
       "12               0.55             -34.71          -44844.10   \n",
       "13               0.55           -6821.87        -5755822.91   \n",
       "14               0.55          -26146.05         -777769.11   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0                0.50               0.48             0.49            0.01   \n",
       "1                0.54               0.52             0.52            0.05   \n",
       "2                0.55               0.52             0.52            0.05   \n",
       "3                0.54               0.52             0.50            0.09   \n",
       "4                0.54               0.52             0.50            0.09   \n",
       "5                0.54               0.52             0.52            0.07   \n",
       "6                0.54               0.52             0.14            0.82   \n",
       "7                0.54               0.52            -0.15            1.41   \n",
       "8                0.54               0.52             0.46            0.19   \n",
       "9                0.54               0.52            -6.78           11.68   \n",
       "10               0.54               0.52          -270.57          517.84   \n",
       "11               0.54               0.52           -24.89           50.79   \n",
       "12               0.54               0.52         -8975.44        17934.33   \n",
       "13               0.54               0.52      -1152528.63      2301648.66   \n",
       "14               0.54               0.52       -160782.71       308659.36   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 6                0.50                0.49   \n",
       "1                 1                0.53                0.52   \n",
       "2                 3                0.54                0.53   \n",
       "3                 5                0.55                0.53   \n",
       "4                 4                0.55                0.54   \n",
       "5                 2                0.55                0.54   \n",
       "6                 8                0.55                0.54   \n",
       "7                 9                0.55                0.54   \n",
       "8                 7                0.55                0.54   \n",
       "9                10                0.56                0.54   \n",
       "10               12                0.56                0.54   \n",
       "11               11                0.56                0.54   \n",
       "12               13                0.56                0.54   \n",
       "13               15                0.56                0.54   \n",
       "14               14                0.56                0.54   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0                 0.50                0.49                0.50   \n",
       "1                 0.55                0.53                0.54   \n",
       "2                 0.55                0.54                0.55   \n",
       "3                 0.56                0.54                0.55   \n",
       "4                 0.56                0.55                0.55   \n",
       "5                 0.56                0.56                0.56   \n",
       "6                 0.56                0.56                0.56   \n",
       "7                 0.56                0.56                0.56   \n",
       "8                 0.56                0.56                0.56   \n",
       "9                 0.56                0.56                0.56   \n",
       "10                0.56                0.56                0.56   \n",
       "11                0.56                0.56                0.56   \n",
       "12                0.56                0.56                0.56   \n",
       "13                0.56                0.56                0.56   \n",
       "14                0.56                0.56                0.56   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0               0.49             0.00  \n",
       "1               0.54             0.01  \n",
       "2               0.54             0.01  \n",
       "3               0.55             0.01  \n",
       "4               0.55             0.01  \n",
       "5               0.55             0.01  \n",
       "6               0.56             0.01  \n",
       "7               0.56             0.01  \n",
       "8               0.56             0.01  \n",
       "9               0.56             0.01  \n",
       "10              0.56             0.01  \n",
       "11              0.56             0.01  \n",
       "12              0.56             0.01  \n",
       "13              0.56             0.01  \n",
       "14              0.56             0.01  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid = pd.DataFrame(grid.cv_results_) \n",
    "df_grid                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with poly features: 0.51\n"
     ]
    }
   ],
   "source": [
    "print(\"Score with poly features: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> Polynomial with degree of 2 is the best model and its performance on the test set is 0.51."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> Part II</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': '/Users/pengshuang/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/breast_cancer.csv'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of load_breast_cancer:\n",
      " dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys of load_breast_cancer:\\n\", data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target names: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(\"Target names:\", data['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    data['data'], data['target'], test_size=0.1 ,random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation score: 0.951\n",
      "best n_neighbors: 7\n",
      "test-set score: 0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "val_scores = []\n",
    "neighbors = np.arange(1,10,2)\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    val_scores.append(knn.score(X_val, y_val))\n",
    "print(f\"best validation score: {np.max(val_scores):.3}\")\n",
    "best_n_neighbors = neighbors[np.argmax(val_scores)]\n",
    "print(\"best n_neighbors:\", best_n_neighbors)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_trainval, y_trainval)\n",
    "print(f\"test-set score: {knn.score(X_test, y_test):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'n_neighbors': 9}\n",
      "test-set score: 0.947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors':  np.arange(1, 20, 2)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5,\n",
    "                   return_train_score=True)\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "print(f\"best parameters: {grid.best_params_}\")\n",
    "\n",
    "print(f\"test-set score: {grid.score(X_test, y_test):.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-4d1b7e0c858b>:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  plt.fill_between(results.param_n_neighbors.astype(np.int),\n",
      "<ipython-input-94-4d1b7e0c858b>:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  plt.fill_between(results.param_n_neighbors.astype(np.int),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa9cd6d9340>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "results.plot('param_n_neighbors', 'mean_train_score')\n",
    "results.plot('param_n_neighbors', 'mean_test_score', ax=plt.gca())\n",
    "plt.fill_between(results.param_n_neighbors.astype(np.int),\n",
    "                 results['mean_train_score'] + results['std_train_score'],\n",
    "                 results['mean_train_score'] - results['std_train_score'], alpha=0.2)\n",
    "plt.fill_between(results.param_n_neighbors.astype(np.int),\n",
    "                 results['mean_test_score'] + results['std_test_score'],\n",
    "                 results['mean_test_score'] - results['std_test_score'], alpha=0.2)\n",
    "plt.legend()\n",
    "#shadow is the standard deviation of the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
